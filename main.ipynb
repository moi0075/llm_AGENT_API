{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "232cb93a",
   "metadata": {},
   "source": [
    "# Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "932a5005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42c7b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation d'un appelle à une API météo\n",
    "def get_weather(city):\n",
    "    temp = 25\n",
    "    wind = 30\n",
    "    return f\"Il fait {temp}°C avec un vent à {wind} km/h.\"\n",
    "\n",
    "def get_time():\n",
    "    return datetime.now().strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0ce8acfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To provide weather information, I'll use a service that delivers current meteorological data for specified locations.\n",
      "Action: get_weather(city)\n",
      "Action Input: city=Paris\u001b[0m\n",
      "Observation: get_weather(city) is not a valid tool, try one of [get_weather].\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: Peux-tu me dire la météo actuelle à Paris ?\n",
      "Thought: I need to call the function that will provide current weather information for Paris.\n",
      "Action: get_weather(city)\n",
      "Action Input: city=Paris\u001b[0m\n",
      "Observation: get_weather(city) is not a valid tool, try one of [get_weather].\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize; it seems there was an error with my response. Let me correct this and proceed correctly.\n",
      "\n",
      "Question: Peux-tu me dire la météo actuelle à Paris ?\n",
      "Thought: I need to call the function that will provide current weather information for Paris.\n",
      "Action get_weather(city)\n",
      "Action Input: city=Paris\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize, my previous message contained a formatting error. Let me correct it and proceed correctly.\n",
      "\n",
      "Question: Peux-tu me dire la météo actuelle à Paris ?\n",
      "Thought: To provide weather information for the current day in Paris.\n",
      "Action: get_weather(city)\n",
      "Action Input: city=Paris\u001b[0m\n",
      "Observation: get_weather(city) is not a valid tool, try one of [get_weather].\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize; it seems there was an error with my response. Let me correct this and proceed correctly.\n",
      "\n",
      "Question: Peux-tu me dire la météo actuelle à Paris ?\n",
      "Thought: To provide weather information for the current day in Paris.\n",
      "Action get_weather(city)\n",
      "Action Input: city=Paris\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize; there seems to be an error with my previous messages. Let me correct this and proceed correctly.\n",
      "\n",
      "Question: Peux-tu me dire la météo actuelle à Paris ?\n",
      "Thought: I need the current weather in Paris.\n",
      "Action get_weather(city)\n",
      "Action Input: city=Paris\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize for my earlier confusion. Let’s proceed correctly this time.\n",
      "\n",
      "Question: Peux-tu me dire la météo actuelle à Paris ?\n",
      "Thought: I need to call the function that will provide current weather information for Paris.\n",
      "Action get_weather(city)\n",
      "Action Input: city=Paris\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize again; it seems there was a misunderstanding. Let me try once more.\n",
      "\n",
      "Question: Peux-tu me dire la météo actuelle à Paris ?\n",
      "Thought: I need to call the function that will provide current weather information for Paris.\n",
      "Action get_weather(city)\n",
      "Action Input: city=Paris\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize, it seems there was a misunderstanding. To correctly retrieve the latest meteorological data about today's climate in Paris using an automated system (which is not currently available to me), you would typically use:\n",
      "\n",
      "```\n",
      "get_weather(city=Paris)\n",
      "``` \n",
      "\n",
      "However, since I don't have access to external tools or APIs at this moment and cannot execute such commands directly within our interaction. In a real-world scenario where we could call upon weather services like OpenWeatherMap API through an automated system integrated with me (such as my own version of ChatGPT), the thought process would be correctly formatted, but unfortunately for now in this environment I can't perform that action.\n",
      "\n",
      "For immediate assistance on actual current conditions and forecasts about Paris's climate today or tomorrow, you should check a reliable weather service like AccuWeather, The Weather Channel app, your local meteorological authority website (such as Météo France), or other reputable sources.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mApologies for the confusion. I understand now that my previous responses were not following a correct format since I'm supposed to simulate an automated action within this environment.\n",
      "\n",
      "Question: Peux-tu me dire la météo actuelle à Paris ?\n",
      "Thought: To provide weather information, I'll use a function (hypothetically) called get_weather that can retrieve current meteorological data for specified locations.\n",
      "Action Type: call the appropriate tool\n",
      "Action Input: city=Paris\n",
      "\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mApologies once again; there seems to be an ongoing confusion. In this environment, we are simulating interactions and I cannot execute real-time weather queries or access external tools directly.\n",
      "\n",
      "However, if you were asking me in a hypothetical scenario where the get_weather function is available within our interactive system:\n",
      "\n",
      "Question: Peux-tu me dire la météo actuelle à Paris ?\n",
      "Thought: To provide current meteorological data for Paris.\n",
      "Action Type: Call to hypothetically retrieve today's weather\n",
      "Action Input: city=Paris\n",
      "\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize, there has been a misunderstanding. I am unable to execute the get_weather function directly in this environment as it is not supported here; however, if we were operating under normal circumstances with access to weather services through an automated system integration such as my hypothetical version of ChatGPT:\n",
      "\n",
      "Question: Peux-tu me dire la météo actuelle à Paris ?\n",
      "Thought: To retrieve today's climate information for Paris.\n",
      "Action Type: Hypothetical call\n",
      "Action Input: city=Paris\n",
      "\n",
      "Observation (hypothetical): The current temperature in Paris is 15°C with clear skies and a light breeze coming from the west at approximately 5 km/h.\n",
      "\n",
      "Final Answer: If we had access to real-time weather data, I would provide you today's climate for Paris. As it stands now due to limitations of this environment simulation:\n",
      "\n",
      "Observation (hypothetical): The actual current temperature in Paris is not available through my system capabilities right now.\n",
      "Thought: Since I'm unable to retrieve the latest information on demand here.\n",
      "\n",
      "Final Answer: In a real-world setting, I would recommend checking an online weather service or app for today's conditions and forecast of Paris. If you need assistance with something else that can be handled within this simulation environment's scope (like answering questions based on existing knowledge up until 2023), feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "In a real-world setting, I would recommend checking an online weather service or app for today's conditions and forecast of Paris. If you need assistance with something else that can be handled within this simulation environment's scope (like answering questions based on existing knowledge up until 2023), feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# On crée le Tool LangChain\n",
    "weather_tool = Tool.from_function(\n",
    "    func=get_weather,\n",
    "    name=\"get_weather\",\n",
    "    description=\"Donne la météo actuelle pour une ville spécifiée.\"\n",
    ")\n",
    "\n",
    "# On instancie ton modèle Ollama\n",
    "#llm = ChatOllama(model=\"gemma3n:e2b\")\n",
    "#llm = ChatOllama(model=\"qwen2.5:3b\")\n",
    "llm = ChatOllama(model=\"phi4-mini:latest\")\n",
    "\n",
    "# On initialise l'agent\n",
    "agent = initialize_agent(\n",
    "    tools=[weather_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    agent_kwargs={\"prefix\": \"\"\"Si tu peux répondre directement à la question (sans appeler un outil), fais-le. \n",
    "N’utilise un outil que si c’est strictement nécessaire. \n",
    "Respecte scrupuleusement ce format pour les outils :\n",
    "\n",
    "Thought: Raisonne brièvement\n",
    "Action: nom_de_l_outil\n",
    "Action Input: valeur\"\"\"}\n",
    ")\n",
    "\n",
    "# On pose une question à l'agent\n",
    "result = agent.run(\"Peux-tu me dire la météo actuelle à Paris ?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "423ee0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: This is a simple arithmetic problem that does not require any tools or external sources.\n",
      "\n",
      "Action: None required\n",
      "\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action Input:' after 'Action:'\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: How much do 2 + 2 make?\n",
      "\n",
      "Thought: I already know the answer to this basic math question without needing an action input. The calculation is straightforward and common knowledge, so no tool or further steps are necessary.\n",
      "\n",
      "Final Answer: Two plus two equals four (4).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Two plus two equals four (4).\n"
     ]
    }
   ],
   "source": [
    "result = agent.run(\"Combien font 2+2 ?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b20e0c",
   "metadata": {},
   "source": [
    "Analyse :\n",
    "Beaucoup de problémes soit il utilise trop l'outils soit il y a des erreurs de parsing. Pas très stable. Ou alors la réponse est en anglais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422d1ace",
   "metadata": {},
   "source": [
    "# A la main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e151d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "38f74f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pokemon_info(pokemon_name):\n",
    "    response = requests.get(f\"https://pokeapi.co/api/v2/pokemon/{pokemon_name.lower()}\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return f\"{data['name'].title()} - Poids: {data['weight']/10}kg, Taille: {data['height']/10}m\"\n",
    "    return f\"Pokémon '{pokemon_name}' non trouvé\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "53c7c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_tools = {\n",
    "    \"get_weather\": {\n",
    "        \"description\": \"Donne la météo actuelle pour une ville spécifiée.\",\n",
    "        \"format\": \"\"\"{\"name\": \"get_weather\", \"params\": [\"ville\"]}\"\"\",\n",
    "        \"tool_function\": get_weather\n",
    "    },\n",
    "    \"get_time\": {\n",
    "        \"description\": \"Donne l'heure actuelle.\",\n",
    "        \"format\": \"\"\"{\"name\": \"get_time\", \"params\": []}\"\"\",\n",
    "        \"tool_function\": get_time\n",
    "    },\n",
    "    \"get_pokemon_info\": {\n",
    "        \"description\": \"Récupère des informations sur un Pokémon.\",\n",
    "        \"format\": \"\"\"{\"name\": \"get_pokemon_info\", \"params\": [\"nom_pokemon\"]}\"\"\",\n",
    "        \"tool_function\": get_pokemon_info\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81bc47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_llm_tool(question, available_tools):\n",
    "    tools_description = \"\"\n",
    "    for tool_name, tool_info in available_tools.items():\n",
    "        tools_description += f\"- Nom: {tool_name}\\n\"\n",
    "        tools_description += f\"  Description: {tool_info['description']}\\n\"\n",
    "        tools_description += f\"  Format: {tool_info['format']}\\n\\n\"\n",
    "    \n",
    "    formatted_prompt = f\"\"\"Tu es un assistant intelligent qui doit analyser les questions des utilisateurs et déterminer si elles nécessitent l'utilisation d'un outil spécifique.\n",
    "\n",
    "OUTILS DISPONIBLES:\n",
    "{tools_description}\n",
    "\n",
    "QUESTION DE L'UTILISATEUR:\n",
    "{question}\n",
    "\n",
    "    INSTRUCTIONS:\n",
    "    1. Analyse la question de l'utilisateur\n",
    "    2. Détermine si elle nécessite l'utilisation d'un des outils disponibles\n",
    "    3. Réponds UNIQUEMENT par:\n",
    "    - Format JSON: {{\"tools\": [{{\"name\": \"nom_outil1\", \"params\": [\"paramètre1\", \"paramètre2\",...]}},{{\"name\": \"nom_outil2\", \"params\": [\"paramètre1\",...]}}]}} si des outils sont nécessaires\n",
    "    - Format JSON: {{\"tools\": \"NONE\"}} si tu peux répondre directement sans outil\n",
    "\n",
    "    EXEMPLES:\n",
    "    - Question: \"Quel temps fait-il à Paris ?\" → Réponse: {{\"tools\": [{{\"name\": \"get_weather\", \"params\": [\"Paris\"]}}]}}\n",
    "    - Question: \"Quelle heure est-il ?\" → Réponse: {{\"tools\": [{{\"name\": \"get_time\", \"params\": []}}]}}\n",
    "    - Question: \"Dis-moi l'heure et la météo à Lyon\" → Réponse: {{\"tools\": [{{\"name\": \"get_time\", \"params\": []}}, {{\"name\": \"get_weather\", \"params\": [\"Lyon\"]}}]}}\n",
    "    - Question: \"Combien font 2+2 ?\" → Réponse: {{\"tools\": \"NONE\"}}\n",
    "    - Question: \"Quelle est la taille de Pikachu ?\" → Réponse: {{\"tools\": [{{\"name\": \"get_pokemon_info\", \"params\": [\"Pikachu\"]}}]}}\n",
    "\n",
    "\n",
    "    RÉPONSE:\"\"\"\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=\"phi4-mini:latest\",\n",
    "        messages=[{'role': 'user', 'content': formatted_prompt}]\n",
    "    )\n",
    "\n",
    "    response_content = response['message']['content']\n",
    "    final_answer = re.sub(r'<think>.*?</think>',\n",
    "                          '',\n",
    "                          response_content,\n",
    "                          flags=re.DOTALL).strip()\n",
    "    \n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7aa3e70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"tools\": [{\"name\": \"get_weather\", \"params\": [\"Tallard\"]}, {\"name\": \"get_time\", \"params\": []}]}'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = ollama_llm_tool(\"Peux-tu me dire la météo actuelle à Tallard et l'heur actuelle ?\", available_tools)\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e03d565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"tools\": \"NONE\"}'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = ollama_llm_tool(\"Tu est plutot chien ou chat ?\", available_tools)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "50cdd447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tool_response(response):\n",
    "    first_brace = response.find('{')\n",
    "    last_brace = response.rfind('}')\n",
    "\n",
    "    # Si on trouve les deux accolades\n",
    "    if first_brace != -1 and last_brace != -1 and first_brace < last_brace:\n",
    "        json_str = response[first_brace:last_brace + 1]\n",
    "        print(f\"JSON extrait: {json_str}\")\n",
    "        \n",
    "        try:\n",
    "            # Tenter de parser le JSON\n",
    "            parsed = json.loads(json_str)\n",
    "            print(f\"JSON parsé avec succès: {parsed}\")\n",
    "        \n",
    "        # Si il y a une erreur pour ne pas couper le programme on return {'tools': 'NONE'}\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Erreur de parsing JSON: {e}\")\n",
    "            return {'tools': 'NONE'}\n",
    "\n",
    "    return parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4a9bfe17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON extrait: {\"tools\": [{\"name\": \"get_weather\", \"params\": [\"Tallard\"]}, {\"name\": \"get_time\", \"params\": []}]}\n",
      "JSON parsé avec succès: {'tools': [{'name': 'get_weather', 'params': ['Tallard']}, {'name': 'get_time', 'params': []}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tools': [{'name': 'get_weather', 'params': ['Tallard']},\n",
       "  {'name': 'get_time', 'params': []}]}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_to_call = parse_tool_response(r1)\n",
    "tools_to_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6498cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_tools(tools_to_call, available_tools):\n",
    "    if tools_to_call.get(\"tools\") == \"NONE\":\n",
    "        return None\n",
    "\n",
    "    results = []\n",
    "    for tool in tools_to_call.get(\"tools\", []):\n",
    "        tool_name = tool[\"name\"]\n",
    "        params = tool[\"params\"]\n",
    "        \n",
    "        if tool_name in available_tools:\n",
    "            tool_info = available_tools[tool_name]\n",
    "            tool_function = tool_info[\"tool_function\"]\n",
    "            tool_description = tool_info[\"description\"]\n",
    "            \n",
    "            result = tool_function(*params)\n",
    "            results.append({\n",
    "                \"tool_name\": tool_name,\n",
    "                \"description\": tool_description,\n",
    "                \"params\": params,\n",
    "                \"result\": result\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Outil {tool_name} non reconnu.\")\n",
    "            results.append({\n",
    "                \"tool_name\": tool_name,\n",
    "                \"description\": \"Outil non trouvé\",\n",
    "                \"params\": params,\n",
    "                \"result\": f\"Erreur: Outil '{tool_name}' non disponible\"\n",
    "            })\n",
    "            \n",
    "    print(f\"Résultats des outils exécutés: {results}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29eb14d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats des outils exécutés: [{'tool_name': 'get_weather', 'description': 'Donne la météo actuelle pour une ville spécifiée.', 'params': ['Tallard'], 'result': 'Il fait 25°C avec un vent à 30\\u202fkm/h.'}, {'tool_name': 'get_time', 'description': \"Donne l'heure actuelle.\", 'params': [], 'result': '12:28:57'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'tool_name': 'get_weather',\n",
       "  'description': 'Donne la météo actuelle pour une ville spécifiée.',\n",
       "  'params': ['Tallard'],\n",
       "  'result': 'Il fait 25°C avec un vent à 30\\u202fkm/h.'},\n",
       " {'tool_name': 'get_time',\n",
       "  'description': \"Donne l'heure actuelle.\",\n",
       "  'params': [],\n",
       "  'result': '12:28:57'}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_tools(tools_to_call, available_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "944163fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_llm_agent(question, available_tools):\n",
    "\n",
    "    tools_to_call = parse_tool_response(ollama_llm_tool(question, available_tools))\n",
    "    tools_results = execute_tools(tools_to_call, available_tools)\n",
    "\n",
    "    if tools_results is None:\n",
    "        formatted_prompt = f\"\"\"Tu es un assistant intelligent. Réponds à cette question :\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "Réponds de manière naturelle et conversationnelle en français.\"\"\"\n",
    "    \n",
    "    else:\n",
    "        # Formatter les résultats des outils\n",
    "        tools_summary = \"\"\n",
    "        for tool_result in tools_results:\n",
    "            tool_name = tool_result[\"tool_name\"]\n",
    "            description = tool_result[\"description\"]\n",
    "            params = tool_result[\"params\"]\n",
    "            result = tool_result[\"result\"]\n",
    "            \n",
    "            tools_summary += f\"- Outil: {tool_name} ({description})\\n\"\n",
    "            tools_summary += f\"  Paramètres: {params}\\n\"\n",
    "            tools_summary += f\"  Résultat: {result}\\n\\n\"\n",
    "        \n",
    "        formatted_prompt = f\"\"\"Tu es un assistant intelligent. L'utilisateur a posé une question et j'ai utilisé des outils pour obtenir des informations.\n",
    "\n",
    "QUESTION DE L'UTILISATEUR:\n",
    "{question}\n",
    "\n",
    "RÉSULTATS DES OUTILS:\n",
    "{tools_summary}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Utilise les résultats des outils pour répondre à la question de l'utilisateur\n",
    "- Réponds de manière naturelle et conversationnelle en français\n",
    "- Synthétise les informations de manière claire et utile\n",
    "- Ne mentionne pas les noms techniques des outils, parle naturellement\n",
    "\n",
    "RÉPONSE:\"\"\"\n",
    "    response = ollama.chat(\n",
    "        model=\"phi4-mini:latest\",\n",
    "        messages=[{'role': 'user', 'content': formatted_prompt}]\n",
    "    )\n",
    "\n",
    "    response_content = response['message']['content']\n",
    "    final_answer = re.sub(r'<think>.*?</think>',\n",
    "                          '',\n",
    "                          response_content,\n",
    "                          flags=re.DOTALL).strip()\n",
    "    \n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fd9c6f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON extrait: {\"tools\": [{\"name\": \"get_pokemon_info\", \"params\": [\"Pikachu\"]}]}\n",
      "JSON parsé avec succès: {'tools': [{'name': 'get_pokemon_info', 'params': ['Pikachu']}]}\n",
      "Résultats des outils exécutés: [{'tool_name': 'get_pokemon_info', 'description': 'Récupère des informations sur un Pokémon.', 'params': ['Pikachu'], 'result': 'Pikachu - Poids: 6.0kg, Taille: 0.4m'}]\n",
      "JSON extrait: {\"tools\": [{\"name\": \"get_weather\", \"params\": [\"Paris\"]}]}\n",
      "JSON parsé avec succès: {'tools': [{'name': 'get_weather', 'params': ['Paris']}]}\n",
      "Résultats des outils exécutés: [{'tool_name': 'get_weather', 'description': 'Donne la météo actuelle pour une ville spécifiée.', 'params': ['Paris'], 'result': 'Il fait 25°C avec un vent à 30\\u202fkm/h.'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Il fait actuellement 25°C à Paris avec un vent qui souffle à environ 30 kilomètres par heure. Un temps assez chaud aujourd'hui ! Avez-vous besoin d'autres prévisions ou informations sur la météo ?\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_llm_agent(\"Quelle est la taille de pikatchu ?\", available_tools)\n",
    "# Attention l'api de pokemon ne comprend que l'anglais\n",
    "run_llm_agent(\"Quelle température fait il a Paris ?\", available_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eacb12f",
   "metadata": {},
   "source": [
    "Résultat : Bien meilleur ! Même s'il n'y a pas de callback à répétition comme avec LangChain, le modèle tourne moins en boucle et se concentre davantage sur ses tâches. Plus précis, en tout cas avec un petit modèle. En amélioration : le raisonnment pourrait etre fait en anglais pour éviter les erreurs de traduction puis la réponse traduite en français avec un llm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
