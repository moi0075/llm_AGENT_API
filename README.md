# LLM Agent API

Agent LLM personnalisÃ© en Python utilisant des outils externes pour rÃ©pondre intelligemment aux questions.

## ğŸš€ FonctionnalitÃ©s

- **Agent intelligent** : DÃ©termine automatiquement les outils nÃ©cessaires
- **SystÃ¨me modulaire** : Facilement extensible
- **Parsing robuste** : Extraction JSON fiable
- **RÃ©ponses naturelles** : En franÃ§ais, conversationnelles
- **Alternative Ã  LangChain** : Plus stable avec les petits modÃ¨les

## ğŸ› ï¸ Outils

- `get_weather(city)` : MÃ©tÃ©o pour une ville
- `get_time()` : Heure actuelle

## âš¡ Installation rapide

```bash
git clone https://github.com/moi0075/llm_AGENT_API.git
cd llm_AGENT_API
pip install ollama requests langchain-community
ollama pull gemma3n:e2b
```

## ğŸš€ Usage

```python
from main import run_llm_agent, available_tools

# Question avec outils
response = run_llm_agent("MÃ©tÃ©o Ã  Paris et heure actuelle ?", available_tools)

# Question simple
response = run_llm_agent("Combien font 2+2 ?", available_tools)
```

## ğŸ—ï¸ Architecture

1. **Analyse** â†’ 2. **Parsing JSON** â†’ 3. **ExÃ©cution outils** â†’ 4. **RÃ©ponse naturelle**

## ğŸ“Š vs LangChain

| Aspect      | Notre implÃ©mentation     | LangChain             |
| ----------- | ------------------------ | --------------------- |
| StabilitÃ©   | âœ… Stable petits modÃ¨les | âŒ Parsing errors     |
| ContrÃ´le    | âœ… Total                 | âŒ Complexe           |
| Performance | âœ… Moins de boucles      | âŒ Boucles frÃ©quentes |

---

**RÃ©sultat** : Plus stable et prÃ©cis que LangChain avec les petits modÃ¨les. Code simple et workflow contrÃ´lÃ©.
